{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "133dcfb8",
   "metadata": {},
   "source": [
    "# todo обновить!\n",
    "\n",
    "На вход модели подается следующий граф планировки:\n",
    "каждая комната и наружный контур имеют ребра от каждой точки контура с своим центрам\n",
    "центры помещений соединенеы между собой ребром, если из одного помещения можно пройти в другое\n",
    "так же все центры комнат соеденены с центром наружного контура\n",
    "все центры дверей и окон соеденины с центрами помещений, к которым они принадлежат\n",
    "\n",
    "все типы объектов (дверь, комната, если да, кто какая) переводятся в ohe и передаются в фичи точек  \n",
    "\n",
    "На выход подаются упрощенные координаты точек помещений (не более 16, если больше, то контур сокращается по приниципу максимизации сохраненной площади, так же удаляются точки которые не сильно влияют на площадь, т.е. небольшие выступы)\n",
    "\n",
    "Кроме точек контура из модели выходят веса точек, если вес точки > 0.5 то точка используется, если менее, не считается точкой контура\n",
    "т.е. поскольку выход координат фиксированной размерности - 16 точек, то некоторые точки нужно удалять.\n",
    "\n",
    "Лосс состоит из 2-ух частей - геометрический и лосс весов\n",
    "Геометрический лосс - сравнение расстояний между точками целевого и предсказанного контура. Поскольку заставлять модель вычивать порядок точек не обязательно, сравнивается исходный и все вариатоы смещения пресказанного контура, в лосс попадает минимальная разница \n",
    "\n",
    "Весовой лосс - разница между весом и либо 0, либо 1, в зависимости от того что ближе\n",
    "\n",
    "На данной стадии лосс эксперементов лосс не отражает визуальную приемлимость картинки  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b136521",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T20:06:58.152250400Z",
     "start_time": "2024-04-23T20:06:58.130246Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pkill -9 -f \"planning\"\n",
    "# 1128\n",
    "# source /home/ubn/Documents/SMC/projects/open_space_planning/.tmp_venv/bin/activate\n",
    "# tensorboard --logdir \"/home/ubn/Documents/SMC/projects/open_space_planning/ds/sw_dw_orig/tensorboard_logs/\" --port 8008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "933a2485",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T00:02:14.091070Z",
     "iopub.status.busy": "2024-04-17T00:02:14.090780Z",
     "iopub.status.idle": "2024-04-17T00:02:14.094174Z",
     "shell.execute_reply": "2024-04-17T00:02:14.093870Z",
     "shell.execute_reply.started": "2024-04-17T00:02:14.091054Z"
    },
    "ExecuteTime": {
     "end_time": "2024-04-23T20:06:54.633033Z",
     "start_time": "2024-04-23T20:06:54.606026100Z"
    }
   },
   "outputs": [],
   "source": [
    "# для работы необходима основные библиотеки\n",
    "# torch_geometric==2.5.0\n",
    "# networkx==3.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84cbf9c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T05:06:51.600380Z",
     "iopub.status.busy": "2024-04-17T05:06:51.600105Z",
     "iopub.status.idle": "2024-04-17T05:06:51.604299Z",
     "shell.execute_reply": "2024-04-17T05:06:51.603749Z",
     "shell.execute_reply.started": "2024-04-17T05:06:51.600366Z"
    },
    "ExecuteTime": {
     "end_time": "2024-04-23T20:07:35.239857400Z",
     "start_time": "2024-04-23T20:07:06.341013100Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib import pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, ReLU, Sequential\n",
    "from torch import Tensor, nn\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import (\n",
    "    EdgeConv,\n",
    "    GATConv,\n",
    "    GATv2Conv,\n",
    "    GCNConv,\n",
    "    GravNetConv,\n",
    "    Linear,\n",
    "    MessagePassing,\n",
    "    Sequential,\n",
    "    XConv,\n",
    "    global_max_pool,\n",
    ")\n",
    "from torch_geometric.nn.pool import max_pool\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "import torch.multiprocessing as mp\n",
    "mp.set_start_method('spawn')\n",
    "\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T20:07:39.032214400Z",
     "start_time": "2024-04-23T20:07:39.011444400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea868405",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T00:02:16.332461Z",
     "iopub.status.busy": "2024-04-17T00:02:16.332247Z",
     "iopub.status.idle": "2024-04-17T00:02:16.335019Z",
     "shell.execute_reply": "2024-04-17T00:02:16.334638Z",
     "shell.execute_reply.started": "2024-04-17T00:02:16.332448Z"
    },
    "ExecuteTime": {
     "end_time": "2024-04-23T20:08:01.751419600Z",
     "start_time": "2024-04-23T20:08:01.717261400Z"
    }
   },
   "outputs": [],
   "source": [
    "def pklsave(v, n):\n",
    "    \"\"\"\n",
    "        Сохраниение сериализуемых данных в формате pickle на диск \n",
    "        args:\n",
    "            v - данные для сохранения,\n",
    "            n - путь к файлу \n",
    "        returns:\n",
    "            None\n",
    "\n",
    "    \"\"\"\n",
    "    with open(n, 'wb') as f:\n",
    "        pickle.dump(v, f)\n",
    "\n",
    "\n",
    "def pkload(n):\n",
    "    \"\"\"\n",
    "        Загрузка сериализуемых данных формате pickle с диска\n",
    "        args:\n",
    "            n - путь к файлу\n",
    "        returns:\n",
    "            сериализованные данные\n",
    "    \"\"\"\n",
    "    with open(n, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e949050",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T00:02:16.335750Z",
     "iopub.status.busy": "2024-04-17T00:02:16.335493Z",
     "iopub.status.idle": "2024-04-17T00:02:16.339092Z",
     "shell.execute_reply": "2024-04-17T00:02:16.338720Z",
     "shell.execute_reply.started": "2024-04-17T00:02:16.335737Z"
    },
    "ExecuteTime": {
     "end_time": "2024-04-23T20:08:07.961350900Z",
     "start_time": "2024-04-23T20:08:07.936504300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Типы подтипы помещений\n",
    "NODE_TYPES = ['DOOR_center',\n",
    "              'DOOR_end',\n",
    "              'DOOR_start',\n",
    "              'ENTRANCE_DOOR_center',\n",
    "              'ENTRANCE_DOOR_end',\n",
    "              'ENTRANCE_DOOR_start',\n",
    "              'WINDOW_center',\n",
    "              'WINDOW_end',\n",
    "              'WINDOW_start',\n",
    "              'apart_center',\n",
    "              'outer_point',\n",
    "              'area_center',\n",
    "              'targ_node',]\n",
    "NODE_SUBTYPES = ['',\n",
    "                 'KITCHEN',\n",
    "                 'PATIO',\n",
    "                 'ELEVATOR',\n",
    "                 'BEDROOM',\n",
    "                 'TERRACE',\n",
    "                 'VOID',\n",
    "                 'STOREROOM',\n",
    "                 'DINING',\n",
    "                 'BATHROOM',\n",
    "                 'GARDEN',\n",
    "                 'KITCHEN_DINING',\n",
    "                 'WINTERGARTEN',\n",
    "                 'ROOM',\n",
    "                 'STAIRCASE',\n",
    "                 'STUDIO',\n",
    "                 'CORRIDOR',\n",
    "                 'LIGHTWELL',\n",
    "                 'OUTDOOR_VOID',\n",
    "                 'LIVING_ROOM']\n",
    "\n",
    "EDGE_TYPES = ['',\n",
    "              'line',\n",
    "              'logic',\n",
    "              'connection_passage',\n",
    "              'connection_door',\n",
    "              'targ_node_edge_0',\n",
    "              'targ_node_edge_1',\n",
    "              'targ_node_edge_2',\n",
    "              'btw_targ_node_edge',]\n",
    "\n",
    "TOTAL_CLASSES = len(NODE_TYPES) - 1 + len(NODE_SUBTYPES)\n",
    "\n",
    "\n",
    "# максимальное количество точек контура\n",
    "MAX_POINTS = 16\n",
    "# эмпирический парамтр кривизны\n",
    "MIN_CURV = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f70929f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T20:11:34.984584Z",
     "start_time": "2024-04-23T20:11:34.972075800Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# переменные обучения\n",
    "CUDA_0 = torch.device('cpu')\n",
    "CUDA_A = torch.device('cpu')\n",
    "# CUDA_0 = torch.device('cpu')\n",
    "CPU_0 = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e921ad5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T00:02:16.339729Z",
     "iopub.status.busy": "2024-04-17T00:02:16.339574Z",
     "iopub.status.idle": "2024-04-17T00:02:16.343629Z",
     "shell.execute_reply": "2024-04-17T00:02:16.343239Z",
     "shell.execute_reply.started": "2024-04-17T00:02:16.339716Z"
    },
    "ExecuteTime": {
     "end_time": "2024-04-23T20:11:37.953802200Z",
     "start_time": "2024-04-23T20:11:37.928168300Z"
    }
   },
   "outputs": [],
   "source": [
    "CPU_0 = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "416f6b9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T00:02:16.345416Z",
     "iopub.status.busy": "2024-04-17T00:02:16.345221Z",
     "iopub.status.idle": "2024-04-17T00:02:20.304808Z",
     "shell.execute_reply": "2024-04-17T00:02:20.304332Z",
     "shell.execute_reply.started": "2024-04-17T00:02:16.345402Z"
    }
   },
   "outputs": [],
   "source": [
    "# загрузка данных с диска\n",
    "Graph = pkload(\n",
    "    'graphs_w_bounds_list.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9aa3c5c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T00:02:20.305494Z",
     "iopub.status.busy": "2024-04-17T00:02:20.305367Z",
     "iopub.status.idle": "2024-04-17T00:02:20.311053Z",
     "shell.execute_reply": "2024-04-17T00:02:20.310537Z",
     "shell.execute_reply.started": "2024-04-17T00:02:20.305481Z"
    },
    "notebookRunGroups": {
     "groupValue": ""
    },
    "ExecuteTime": {
     "end_time": "2024-04-23T20:15:19.120844700Z",
     "start_time": "2024-04-23T20:15:11.596494200Z"
    }
   },
   "outputs": [],
   "source": [
    "# разделение данных на обучающию и валидационную выборки\n",
    "Graph_train, Graph_val = train_test_split(\n",
    "    Graph, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6f7e0fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T00:02:20.312146Z",
     "iopub.status.busy": "2024-04-17T00:02:20.311810Z",
     "iopub.status.idle": "2024-04-17T00:02:20.314950Z",
     "shell.execute_reply": "2024-04-17T00:02:20.314524Z",
     "shell.execute_reply.started": "2024-04-17T00:02:20.312125Z"
    },
    "ExecuteTime": {
     "end_time": "2024-04-23T20:15:31.195840100Z",
     "start_time": "2024-04-23T20:15:31.193209600Z"
    }
   },
   "outputs": [],
   "source": [
    "def close_cont(cont):\n",
    "    \"\"\"\n",
    "        Добавление первой точки в конец контура для массива numpy\n",
    "        args:\n",
    "            cont:nunmpy.array : размер Nx2\n",
    "        returns:\n",
    "            nunmpy.array\n",
    "    \"\"\"\n",
    "    return np.concatenate((cont, cont[0:1]), axis=0)\n",
    "\n",
    "\n",
    "def close_cont_trch(cont):\n",
    "    \"\"\"\n",
    "        Добавление первой точки в конец контура для тензоров\n",
    "        args:\n",
    "            cont:torch.tensor : размер Nx2\n",
    "        returns:\n",
    "            torch.tensor\n",
    "    \"\"\"\n",
    "    return torch.cat((cont, cont[0:1]), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd11986a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T00:02:20.315681Z",
     "iopub.status.busy": "2024-04-17T00:02:20.315459Z",
     "iopub.status.idle": "2024-04-17T00:02:20.320804Z",
     "shell.execute_reply": "2024-04-17T00:02:20.320371Z",
     "shell.execute_reply.started": "2024-04-17T00:02:20.315667Z"
    },
    "ExecuteTime": {
     "end_time": "2024-04-23T20:15:31.233205100Z",
     "start_time": "2024-04-23T20:15:31.207843600Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_inds_from_gr(graph, string_list=[], keys_list=[]):\n",
    "    \"\"\"\n",
    "    Получение всех ребер, в свойствах которых есть любая из указанных строк\n",
    "    Args:\n",
    "        gr - граф\n",
    "        string_list - список строк, по котоым ищется ребро\n",
    "    returns:\n",
    "        тензор индексов ребер размером 2xN\n",
    "    \"\"\"\n",
    "\n",
    "    edge_index = []\n",
    "    for n0, n1, d in graph.edges(data=True):\n",
    "        if d.get(\"type\", \"\") in string_list or any([k in d.keys() for k in keys_list]):\n",
    "            edge_index.append([n0, n1])\n",
    "    edge_index = list(zip(*edge_index))\n",
    "\n",
    "    return torch.tensor(edge_index, dtype=torch.long, device=CUDA_A)\n",
    "\n",
    "\n",
    "def get_inds_of_nodes(graph, string_list):\n",
    "    \"\"\"\n",
    "    Получение всех вершин, в свойствах которых есть любая из указанных строк\n",
    "    Args:\n",
    "        gr - граф\n",
    "        string_list - список строк, по котоым ищется вершина\n",
    "    returns:\n",
    "        тензор индексов вершин размером N\n",
    "    \"\"\"\n",
    "\n",
    "    nodes_indices = []\n",
    "    for n, d in graph.nodes(data=True):\n",
    "        if d[\"type\"] in string_list:\n",
    "            nodes_indices.append(n)\n",
    "\n",
    "    return nodes_indices\n",
    "\n",
    "\n",
    "def rev_edges(edge_index):\n",
    "    \"\"\"\n",
    "    реверс направлений ребер\n",
    "    args:\n",
    "        edge_index:torch.tensor - массив индексов 2хN\n",
    "    returns:\n",
    "        массив индексов 2хN\n",
    "    \"\"\"\n",
    "    return torch.cat([edge_index[1].unsqueeze(0), edge_index[0].unsqueeze(0)], 0)\n",
    "\n",
    "\n",
    "def add_reverse_dir(edge_index):\n",
    "    \"\"\"\n",
    "    добавлние обратного направления ребер\n",
    "    args:\n",
    "        edge_index:torch.tensor - массив индексов 2хN\n",
    "    returns:\n",
    "        массив индексов 2х(N*2)\n",
    "    \"\"\"\n",
    "    rev = rev_edges(edge_index)\n",
    "    edge_index = torch.cat((edge_index, rev), 1)\n",
    "    \n",
    "    return edge_index\n",
    "\n",
    "\n",
    "def add_self_loop_dir(edge_index):\n",
    "    \"\"\"\n",
    "    добавление self-loop ребер\n",
    "    args:\n",
    "        edge_index:torch.tensor - массив индексов 2хN\n",
    "    returns:\n",
    "        массив индексов 2х(N*2)\n",
    "    \"\"\"\n",
    "    slf = edge_index[1][None, :].repeat(2, 1)\n",
    "    edge_index = torch.cat((edge_index, slf), 1)\n",
    "\n",
    "    return edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "733fc4da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T00:02:20.321540Z",
     "iopub.status.busy": "2024-04-17T00:02:20.321336Z",
     "iopub.status.idle": "2024-04-17T00:02:20.323305Z",
     "shell.execute_reply": "2024-04-17T00:02:20.322946Z",
     "shell.execute_reply.started": "2024-04-17T00:02:20.321527Z"
    },
    "ExecuteTime": {
     "end_time": "2024-04-23T20:15:31.233205100Z",
     "start_time": "2024-04-23T20:15:31.215870500Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import itertools\n",
    "NUMBER_OF_BORDER_POINTS_DATASET = 11\n",
    "NUMBER_OF_BORDER_POINTS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f717c21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14e64893",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T05:05:49.040766Z",
     "iopub.status.busy": "2024-04-17T05:05:49.040522Z",
     "iopub.status.idle": "2024-04-17T05:05:49.130355Z",
     "shell.execute_reply": "2024-04-17T05:05:49.129982Z",
     "shell.execute_reply.started": "2024-04-17T05:05:49.040753Z"
    },
    "ExecuteTime": {
     "end_time": "2024-04-23T20:15:31.386203Z",
     "start_time": "2024-04-23T20:15:31.296219Z"
    }
   },
   "outputs": [],
   "source": [
    "def ttf(data):\n",
    "    \"\"\"\n",
    "        проеобразование в тензор float32\n",
    "        args:\n",
    "            data:List | numpy.array | torch.tensor - данные для преобразования\n",
    "        returns:\n",
    "            тензор torch.float32\n",
    "    \"\"\"\n",
    "    return torch.tensor(data, dtype=torch.float32, device=CUDA_A)\n",
    "\n",
    "\n",
    "def opposite_node(nodes, node):\n",
    "    \"\"\"\n",
    "        возвращает противоположный от данного узла узел в ребре\n",
    "    \"\"\"\n",
    "    return list(set(nodes) - set([node]))[0]\n",
    "\n",
    "\n",
    "def ttl(data):\n",
    "    \"\"\"\n",
    "        проеобразование в тензор long\n",
    "        args:\n",
    "            data:List | numpy.array | torch.tensor - данные для преобразования\n",
    "        returns:\n",
    "            тензор torch.long\n",
    "    \"\"\"\n",
    "    return torch.tensor(data, dtype=torch.long, device=CUDA_A)\n",
    "\n",
    "\n",
    "def get_curv_area(countour):\n",
    "    \"\"\"\n",
    "        Получение кривизны точек\n",
    "        args:\n",
    "            numpy - контур\n",
    "        returns:\n",
    "            массив - площадь параллепипеда образованного входящей и исходящей линиями, \n",
    "            массив - площадь параллепипеда образованного входящей линией повернутой на 90 градусов и исходящей линиями\n",
    "    \"\"\"\n",
    "    # круговое смещение точек контура\n",
    "    countour_rolled = np.roll(countour, -1, 0)\n",
    "\n",
    "    # подсчет векторов\n",
    "    vects = countour_rolled - countour\n",
    "\n",
    "    # круговое смещение векторов\n",
    "    vects_prev = np.roll(vects, 1, 0)\n",
    "\n",
    "    # поворот смещенных векторов на 90 градусов\n",
    "    vects_prev_ort = np.roll(vects_prev, shift=(0, 1), axis=(0, 1))\n",
    "    vects_prev_ort[:, 1] = - vects_prev_ort[:, 1]\n",
    "\n",
    "    return np.abs(np.cross(vects_prev, vects)), np.abs((vects_prev_ort * vects).sum(1))\n",
    "\n",
    "\n",
    "def cleanup_and_add_target_nodes_to_graph(graph):\n",
    "    \"\"\"\n",
    "        Очистка и достраивание графа\n",
    "        args:\n",
    "            graphs:[nx.Digraph] - список графов\n",
    "        returns:\n",
    "            [nx.Digraph] - список графов\n",
    "    \"\"\"\n",
    "\n",
    "    # создание направленного графа\n",
    "    graph = nx.DiGraph(graph)\n",
    "    edges_to_remove = []\n",
    "    nodes_to_remove = set()\n",
    "\n",
    "    # удаление лишних узлов и граней\n",
    "    for i, j in graph.edges():\n",
    "        if graph.nodes[i].get('type', '') == \"DOOR_center\" or \\\n",
    "            graph.nodes[i].get('type', '') == \"DOOR_start\" or \\\n",
    "                graph.nodes[i].get('type', '') == \"DOOR_end\":\n",
    "            edges_to_remove.append((i, j))\n",
    "            nodes_to_remove.add(i)\n",
    "\n",
    "    for e in edges_to_remove:\n",
    "        graph.remove_edge(*e)\n",
    "\n",
    "    for n in nodes_to_remove:\n",
    "        graph.remove_node(n)\n",
    "\n",
    "    # реиндексация\n",
    "    graph = nx.relabel.convert_node_labels_to_integers(\n",
    "        graph, first_label=0, ordering='default'\n",
    "    )\n",
    "    graph = nx.DiGraph(graph)\n",
    "    # количество узлов\n",
    "    current_node = graph.number_of_nodes()\n",
    "\n",
    "    # в сэмпл входит только один граф планировки\n",
    "\n",
    "    # достраивание графа - добавление узлов, попарно соединяющих центры помещений\n",
    "    area_center_indices = get_inds_of_nodes(graph, \"area_center\")\n",
    "    links_btw_all_areas = itertools.combinations(area_center_indices, r=2)\n",
    "\n",
    "    for i, j in links_btw_all_areas:\n",
    "        # создание ребер и их свойств\n",
    "        graph.add_edge(i, j, **{\n",
    "            'possible_border': True,\n",
    "            # 'targ_node_edge_index': 0\n",
    "        })\n",
    "        graph.add_edge(j, i, **{\n",
    "            'possible_border': True,\n",
    "            # 'targ_node_edge_index': 0\n",
    "        })\n",
    "        graph.add_node(current_node, **{\n",
    "            'pos': np.array([0.0, 0.0]),\n",
    "            'in_walls_doors': np.zeros((2)),\n",
    "            'type': 'targ_node'\n",
    "        })\n",
    "        graph.add_edge(i, current_node, **{\n",
    "            # 'targ_node_edge': True,\n",
    "            'type': f'targ_node_edge_{0}',\n",
    "            # 'targ_node_edge_index': 0\n",
    "        })\n",
    "        graph.add_edge(j, current_node, **{\n",
    "            # 'targ_node_edge': True,\n",
    "            'type': f'targ_node_edge_{NUMBER_OF_BORDER_POINTS-1}',\n",
    "            # 'targ_node_edge_index': NUMBER_OF_BORDER_POINTS-1\n",
    "        })\n",
    "        prev_node = current_node\n",
    "        current_node = current_node + 1\n",
    "\n",
    "        for p in range(1, NUMBER_OF_BORDER_POINTS):\n",
    "            graph.add_node(current_node, **{\n",
    "                'pos': np.array([0.0, 0.0]),\n",
    "                'in_walls_doors': np.zeros((2)),\n",
    "                'type': 'targ_node'\n",
    "            })\n",
    "\n",
    "            graph.add_edge(i, current_node, **{\n",
    "                # 'targ_node_edge': True,\n",
    "                'type': f'targ_node_edge_{p}',\n",
    "                # 'targ_node_edge_index': p\n",
    "            })\n",
    "            graph.add_edge(j, current_node, **{\n",
    "                # 'targ_node_edge': True,\n",
    "                'type': f'targ_node_edge_{NUMBER_OF_BORDER_POINTS-1-p}',\n",
    "                # 'targ_node_edge_index': NUMBER_OF_BORDER_POINTS-1-p\n",
    "            })\n",
    "\n",
    "            graph.add_edge(current_node, prev_node, **{\n",
    "                'targ_node_edge': True,\n",
    "                'type': 'btw_targ_node_edge'\n",
    "            })\n",
    "            #\n",
    "            graph.add_edge(prev_node, current_node, **{\n",
    "                'targ_node_edge': True,\n",
    "                'type': 'btw_targ_node_edge'\n",
    "            })\n",
    "\n",
    "            prev_node = current_node\n",
    "\n",
    "            current_node = current_node + 1\n",
    "\n",
    "        # объединение массивов in_walls и in_doors в один\n",
    "        data = graph.get_edge_data(i, j)\n",
    "        if not data.get('border', None) is None:\n",
    "            for e, r in enumerate(range(0, NUMBER_OF_BORDER_POINTS_DATASET, 5)):\n",
    "                ind = current_node - NUMBER_OF_BORDER_POINTS + e\n",
    "\n",
    "                graph.nodes[ind].update({\n",
    "                    'target_pos': data.get('border')[r],\n",
    "                    'in_walls_doors': [\n",
    "                        data.get('in_walls')[r],\n",
    "                        data.get('in_doors')[r]\n",
    "                    ],\n",
    "                    'exists': [1]\n",
    "                })\n",
    "\n",
    "    # задание индексов OHE\n",
    "    for n, d in graph.nodes(data=True):\n",
    "        ind = NODE_TYPES.index(d['type']) + \\\n",
    "            NODE_SUBTYPES.index(d.get('subtype', ''))\n",
    "        d = {'ohe_index': ind, 'pos': d['pos']}\n",
    "        \n",
    "    return graph\n",
    "\n",
    "\n",
    "tmp_cache_dict = {}\n",
    "\n",
    "\n",
    "LEN_EDGE_FEATS = 1 + 1 + 1 + len(EDGE_TYPES)\n",
    "\n",
    "ANGLE_BINS = 180\n",
    "\n",
    "\n",
    "def calc_align_vect(vects):\n",
    "    \"\"\"\n",
    "        Расчет наиболее частого вектора\n",
    "        args:\n",
    "            vects - вектора\n",
    "        returns:\n",
    "            вектор\n",
    "    \"\"\"\n",
    "\n",
    "    # количество корзин\n",
    "    bins_vects = np.zeros((ANGLE_BINS, 2))\n",
    "\n",
    "    # итерация по векторам\n",
    "    for vec in vects:\n",
    "        ang = np.arctan2(*vec)/np.pi*180\n",
    "        if ang < 0:\n",
    "            ang = ang + 180\n",
    "\n",
    "        # индекс корзины\n",
    "        ang_ind = int(ang/360*ANGLE_BINS)\n",
    "\n",
    "        # прибавление или вычитание вектора, так чтобы длинна в корзине увеличилась\n",
    "        if np.linalg.norm(bins_vects[ang_ind] + vec) > np.linalg.norm(bins_vects[ang_ind]):\n",
    "            bins_vects[ang_ind] = bins_vects[ang_ind] + vec\n",
    "        else:\n",
    "            bins_vects[ang_ind] = bins_vects[ang_ind] - vec\n",
    "\n",
    "    # длины векторов\n",
    "    bins_vects_length = np.linalg.norm(bins_vects, axis=1)\n",
    "    max_ind = bins_vects_length.argmax()\n",
    "\n",
    "    # вектор с максимальной длинной\n",
    "    align_vect = bins_vects[max_ind]\n",
    "    align_vect = align_vect/np.linalg.norm(align_vect)\n",
    "\n",
    "    return align_vect\n",
    "\n",
    "\n",
    "def graph_to_data(graph):\n",
    "    \"\"\"\n",
    "        Преобразование графа в кортеж тензоров\n",
    "        args:\n",
    "            graph:nx.Digraph - граф\n",
    "        returns:\n",
    "            кортеж тензоров\n",
    "    \"\"\"\n",
    "    def create_edge_feats_tensor(graph, edges_index_tensor):\n",
    "        \"\"\"\n",
    "            Преобразование свойств ребер в графа в фичи\n",
    "            args:\n",
    "                graph:nx.DiGraph - граф,\n",
    "                edges_index_tensor:torch.Tensor - ребра рафа (2xN)\n",
    "            returns:\n",
    "                тензор фичей (NxLEN_EDGE_FEATS)\n",
    "        \"\"\"\n",
    "        # инициализация пустого массива\n",
    "        edges_feats = torch.zeros(\n",
    "            (edges_index_tensor.shape[1], LEN_EDGE_FEATS), dtype=torch.float32, device=CUDA_A)\n",
    "        \n",
    "        # итерация по ребрам\n",
    "        for ind in range(edges_index_tensor.shape[1]):\n",
    "            i = int(edges_index_tensor[0, ind])\n",
    "            j = int(edges_index_tensor[1, ind])\n",
    "            edge_data = graph[i][j]\n",
    "\n",
    "            # получение фичей ребра\n",
    "            edge_feats = get_edge_feats(graph, i, j, edge_data)\n",
    "\n",
    "            edges_feats[ind] = edge_feats\n",
    "        return edges_feats\n",
    "\n",
    "    def get_edge_feats(graph, i, j, edge_data):\n",
    "        \"\"\"\n",
    "            Преобразование свойств ребра в фичи\n",
    "            arg:\n",
    "                graph - граф, \n",
    "                i - индекс узла i, \n",
    "                j - индекс узла j, \n",
    "                edge_data - словарь свойств ребра\n",
    "        \"\"\"\n",
    "        # инициализация пустого массива\n",
    "        edge_feats = torch.zeros(\n",
    "            (LEN_EDGE_FEATS), dtype=torch.float32, device=CUDA_A)\n",
    "\n",
    "        length = 0.0\n",
    "        # определение длинны для некоторых ребер\n",
    "        if edge_data.get('type', '') in [\n",
    "            'line',\n",
    "            'logic',\n",
    "            'connection_passage',\n",
    "            'connection_door'\n",
    "        ] or not edge_data.get('border', None) is None:\n",
    "            pos_i = graph.nodes[i].get('pos')\n",
    "            pos_j = graph.nodes[j].get('pos')\n",
    "            length = np.linalg.norm(pos_i-pos_j)\n",
    "        edge_feats[0] = length\n",
    "\n",
    "        # наличие границы между помещениями\n",
    "        if 'border' in edge_data.keys():\n",
    "            edge_feats[1] = 1.0\n",
    "\n",
    "        # возможность границы между помещениями\n",
    "        if 'possible_border' in edge_data.keys():\n",
    "            edge_feats[2] = 1.0\n",
    "\n",
    "        # запись в тензор\n",
    "        ohe_ind = EDGE_TYPES.index(edge_data.get('type', ''))\n",
    "        edge_feats[3+ohe_ind] = 1.0\n",
    "\n",
    "        return edge_feats\n",
    "\n",
    "    nodes_count = graph.number_of_nodes()\n",
    "    # area_centers = get_inds_of_nodes(graph, [\"area_center\"])\n",
    "    # apart_center = get_inds_of_nodes(graph, [\"apart_center\"])[0]\n",
    "    # edge_index_aprt_cnt_to_areas = ttl(\n",
    "    #    [[apart_center] * len(area_centers), area_centers])\n",
    "\n",
    "    # edge_index_targ_all_btw_areas = get_inds_from_gr(\n",
    "    #    graph, [], keys_list=['possible_border'])\n",
    "\n",
    "    # сбор индексов ребер к целевым узлам\n",
    "    edge_index_targ_node_edge_0 = get_inds_from_gr(graph, ['targ_node_edge_0'])\n",
    "    edge_index_targ_node_edge_1 = get_inds_from_gr(graph, ['targ_node_edge_1'])\n",
    "    edge_index_targ_node_edge_2 = get_inds_from_gr(graph, ['targ_node_edge_2'])\n",
    "\n",
    "    # сбор индексов ребер остальных узлов\n",
    "    edge_index_first_graph = torch.tensor(\n",
    "        list(zip(*[\n",
    "            (u, v) for u, v in list(graph.edges) if not 'targ_node_edge' in graph[u][v].keys()\n",
    "        ])),\n",
    "        dtype=torch.long, device=CUDA_A\n",
    "    )\n",
    "\n",
    "    # фичи основного графа\n",
    "    edge_feats_first_graph = create_edge_feats_tensor(\n",
    "        graph, edge_index_first_graph)\n",
    "\n",
    "    # добавлени наружного контура\n",
    "    edge_index_line = get_inds_from_gr(graph, ['line'])\n",
    "\n",
    "    # \n",
    "    vects = []\n",
    "    for i in range(edge_index_line.shape[1]):\n",
    "        i_pos = graph.nodes[int(edge_index_line[0, i])].get('pos')\n",
    "        j_pos = graph.nodes[int(edge_index_line[1, i])].get('pos')\n",
    "        vects.append(j_pos-i_pos)\n",
    "    vects = np.array(vects)\n",
    "\n",
    "    align_vect = torch.tensor(calc_align_vect(vects))\n",
    "    # получение ребер между центром квартиры и наружнымконтуром\n",
    "    edge_index_from_line_to_cnt = get_inds_from_gr(graph, ['logic'])\n",
    "    \n",
    "\n",
    "    # ребра перемещения человека между комнатами\n",
    "    area_center_indices = get_inds_of_nodes(graph, \"apart_center\")\n",
    "    edge_index_all_nodes = torch.arange(\n",
    "        nodes_count, dtype=torch.long, device=CUDA_A)\n",
    "    \n",
    "    # ребра между центром кавртиры и всеми узлами\n",
    "    edge_index_from_center_to_all_nodes = torch.cat(\n",
    "        (ttl(area_center_indices[0:1]).repeat((1, edge_index_all_nodes.shape[0])), edge_index_all_nodes[None, :]), dim=0)\n",
    "\n",
    "    x = torch.zeros((nodes_count, TOTAL_CLASSES),\n",
    "                    dtype=torch.float32, device=CUDA_A)\n",
    "    # edge_index_all_nodes = torch.arange(\n",
    "    #    nodes_count, dtype=torch.long, device=CUDA_A)\n",
    "\n",
    "    pos = torch.zeros((nodes_count, 2), dtype=torch.float, device=CUDA_A)\n",
    "    feats_targ = torch.zeros(\n",
    "        (nodes_count, 6), dtype=torch.float, device=CUDA_A)\n",
    "\n",
    "    # сбор нанных со всех узлов, задание ohe исходного массива фичей точек\n",
    "    for i in range(nodes_count):\n",
    "        data = graph.nodes[i]\n",
    "        ind = data.get('ohe_index', -1)\n",
    "        x[i, ind] = 1.0\n",
    "        pt = ttf(data.get('pos'))\n",
    "        pos[i, 0] = pt[0]\n",
    "        pos[i, 1] = pt[1]\n",
    "        feats_targ[i, :] = ttf(list(data.get('target_pos', [0.0, 0.0])) + list(\n",
    "            data.get('in_walls_doors', [0.0, 0.0])) + data.get('exists', [0.0]) + [(data.get('type', \"\") == 'targ_node') * 1])\n",
    "\n",
    "    # ребра между целевыми узлами\n",
    "    edge_index_debug_btw_targ_node_edge = get_inds_from_gr(\n",
    "        graph, ['btw_targ_node_edge'])\n",
    "    # индекс графа для последующей проверки\n",
    "\n",
    "    return (align_vect,\n",
    "            edge_index_from_center_to_all_nodes,\n",
    "            edge_index_first_graph,\n",
    "            edge_feats_first_graph,\n",
    "            edge_index_targ_node_edge_0,\n",
    "            edge_index_targ_node_edge_1,\n",
    "            edge_index_targ_node_edge_2,\n",
    "            edge_index_line,\n",
    "            edge_index_from_line_to_cnt,\n",
    "            x,\n",
    "            pos,\n",
    "            feats_targ,\n",
    "            edge_index_debug_btw_targ_node_edge,\n",
    "            )\n",
    "\n",
    "\n",
    "def graphs_to_data(graphs):\n",
    "    \"\"\"\n",
    "        Доработка и преобразование графов в список кортежей тензоров\n",
    "        args:\n",
    "            graphs:[nx.Digraph] - список графов\n",
    "        returns:\n",
    "            список кортежей тензоров\n",
    "    \"\"\"\n",
    "    samples_data = []\n",
    "    prev_time = 0\n",
    "\n",
    "    for i, graph in enumerate(graphs):\n",
    "        if time.time() - prev_time > 5:\n",
    "            clear_output(wait=True)\n",
    "            print(i, len(graphs))\n",
    "            prev_time = time.time()\n",
    "        \n",
    "        # очистка и достраивание \n",
    "        graph = cleanup_and_add_target_nodes_to_graph(graph)\n",
    "\n",
    "        # перобразование в список кортежей тензоров\n",
    "        samples_data.append(graph_to_data(graph))\n",
    "\n",
    "    return samples_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "461acd2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T20:15:44.319840600Z",
     "start_time": "2024-04-23T20:15:31.389203700Z"
    }
   },
   "outputs": [],
   "source": [
    "# загрузка треннировочных данных\n",
    "if os.path.isfile('train_data_v01.pkl'):\n",
    "    train_data = pkload('train_data_v01.pkl')\n",
    "else:\n",
    "    train_data = graphs_to_data(Graph_train)\n",
    "    pklsave(train_data, 'train_data_v01.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7cbb4da2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T20:16:01.805876800Z",
     "start_time": "2024-04-23T20:15:55.100421500Z"
    }
   },
   "outputs": [],
   "source": [
    "# загрузка проверочных данных\n",
    "if os.path.isfile('val_data_v01.pkl'):\n",
    "    val_data = pkload('val_data_v01.pkl')\n",
    "else:\n",
    "    val_data = graphs_to_data(Graph_val)\n",
    "    pklsave(val_data, 'val_data_v01.pkl')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e224dc8b",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "def data_to_cpu(train_data):\n",
    "    for i in range(len(train_data)):    \n",
    "        train_data[i] = [train_data[i][j].to(CPU_0) for j in range(len(train_data[i]))]\n",
    "        \n",
    "data_to_cpu(train_data)\n",
    "data_to_cpu(val_data)\n",
    "\n",
    "pklsave(train_data,'train_data_v01.pkl')\n",
    "pklsave(val_data,'val_data_v01.pkl')\n",
    "stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f9de211",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T20:16:01.816097400Z",
     "start_time": "2024-04-23T20:16:01.812878800Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class DataGen():\n",
    "    def __init__(self, data_):\n",
    "        \"\"\"\n",
    "            Инициализация генератора\n",
    "            args:\n",
    "                self - экземпляр класса\n",
    "                graphs - графы\n",
    "            returns:\n",
    "                None\n",
    "        \"\"\"\n",
    "        # self.graphs = graphs\n",
    "        self.data_ = data_\n",
    "        self.len_graphs = len(self.data_)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len_graphs\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "            Генерация одного сэмпла обучения\n",
    "            args:\n",
    "                self - экземпляр класса,\n",
    "                key:int - порядковый номер сэмпла\n",
    "            returns:\n",
    "                экземпляр класса Data (данные одного сэмпла)\n",
    "        \"\"\"\n",
    "        key = key % self.len_graphs\n",
    "\n",
    "        # выбор графа по ключу\n",
    "        data = self.data_[key]\n",
    "\n",
    "        # копирование тензоров\n",
    "        data = [i.clone() for i in data]\n",
    "\n",
    "        (align_vect,\n",
    "         edge_index_from_center_to_all_nodes,\n",
    "            edge_index_first_graph,\n",
    "            edge_feats_first_graph,\n",
    "            edge_index_targ_node_edge_0,\n",
    "            edge_index_targ_node_edge_1,\n",
    "            edge_index_targ_node_edge_2,\n",
    "            edge_index_line,\n",
    "            edge_index_from_line_to_cnt,\n",
    "            x,\n",
    "            pos,\n",
    "            feats_targ,\n",
    "            edge_index_debug_btw_targ_node_edge,\n",
    "         ) = data\n",
    "\n",
    "        # индекс графрв для узлов батча\n",
    "        debug_sg_ind = ttl([key]).repeat((x.shape[0]))\n",
    "        # align_vect[1],align_vect[0] = -align_vect[0],align_vect[1]\n",
    "\n",
    "        # угол поворота = выравнивающий угол, + случайно * 90\n",
    "        alf = -np.arctan2(float(align_vect[0]), float(align_vect[1])\n",
    "                          ) + int(np.random.rand()*4) * np.pi * 0.5\n",
    "\n",
    "        # флип пока не рассматривается\n",
    "        # flip_hor = int(np.random.rand()*2)\n",
    "        # flip_vert = int(np.random.rand()*2)\n",
    "\n",
    "        # матрица поворота\n",
    "        rot_matr = ttf([[np.cos(alf), -np.sin(alf)],\n",
    "                       [np.sin(alf), np.cos(alf),]])\n",
    "\n",
    "        # поворот исходных координат\n",
    "        pos = torch.matmul(pos[:, None, :].clone(), rot_matr)[:, 0, :]\n",
    "        # if flip_hor == 1:\n",
    "        #    pos[:,0] = - pos[:,0]\n",
    "#\n",
    "        # if flip_vert == 1:\n",
    "        #    pos[:,1] = - pos[:,1]\n",
    "#\n",
    "        # flip_targ_edges = (flip_vert + flip_hor) % 2 == 1\n",
    "\n",
    "        # поворот целевых координат\n",
    "        targ_pos = feats_targ[:, :2].clone()\n",
    "        targ_pos = torch.matmul(targ_pos[:, None, :], rot_matr)[:, 0, :]\n",
    "\n",
    "        # if flip_hor == 1:\n",
    "        #    targ_pos[:,0] = - targ_pos[:,0]\n",
    "#\n",
    "        # if flip_vert == 1:\n",
    "        #    targ_pos[:,1] = - targ_pos[:,1]\n",
    "\n",
    "        feats_targ[:, :2] = targ_pos\n",
    "\n",
    "        # обратная матрица поворота\n",
    "        rev_rot_matr = rot_matr.clone()\n",
    "        rev_rot_matr[0, 1] = - rev_rot_matr[0, 1]\n",
    "        rev_rot_matr[1, 0] = - rev_rot_matr[1, 0]\n",
    "        rev_rot_matr = rev_rot_matr[None, :]\n",
    "        rev_rot_matr = rev_rot_matr.repeat((x.shape[0], 1, 1))\n",
    "\n",
    "        data = Data(\n",
    "            # ребра от центра до всех узлов\n",
    "            edge_index_from_center_to_all_nodes=edge_index_from_center_to_all_nodes,\n",
    "            # ребра основаного графа\n",
    "            edge_index_first_graph=edge_index_first_graph,\n",
    "            # фичи ребер основного графа\n",
    "            edge_feats_first_graph=edge_feats_first_graph,\n",
    "            # ребра дополнительного графа к 0-ой точке границы\n",
    "            edge_index_targ_node_edge_0=edge_index_targ_node_edge_0,\n",
    "            # ребра дополнительного графа к 1-ой точке границы\n",
    "            edge_index_targ_node_edge_1=edge_index_targ_node_edge_1,\n",
    "            # ребра дополнительного графа к 2-ой точке границы\n",
    "            edge_index_targ_node_edge_2=edge_index_targ_node_edge_2,\n",
    "            # ребра наружного конттура\n",
    "            edge_index_line=edge_index_line,\n",
    "            # ребра от наружного конттура к центру\n",
    "            edge_index_from_line_to_cnt=edge_index_from_line_to_cnt,\n",
    "            # фичи узлов\n",
    "            x=x,\n",
    "            # исходные позиции узлов\n",
    "            pos=pos,\n",
    "            # целевые фичи узлов\n",
    "            feats_targ=feats_targ,\n",
    "            # ребра между целевыми точками\n",
    "            edge_index_debug_btw_targ_node_edge=edge_index_debug_btw_targ_node_edge,\n",
    "            # индекс графрв для узлов батча\n",
    "            debug_sg_ind=debug_sg_ind,\n",
    "            # мотрица обратного поворота, для отображения\n",
    "            debug_rev_rot_matr=rev_rot_matr,\n",
    "            # индексы всех узлов\n",
    "            edge_index_debug_all_node_indices=torch.arange(\n",
    "                (x.shape[0]), dtype=torch.long, device=CUDA_A),\n",
    "        )\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "af3d26c3",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# тест\n",
    "data_gen = DataGen(train_data)\n",
    "\n",
    "loader = DataLoader(data_gen, follow_batch=[\n",
    "                    'x'], batch_size=1, num_workers=0, shuffle=False)\n",
    "\n",
    "\n",
    "itr = iter(loader)\n",
    "batch = next(itr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65c53239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 % 2"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a47c6c31",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "\n",
    "\n",
    "data_gen = DataGen(train_data[:1])\n",
    "loader = DataLoader(data_gen, follow_batch=[\n",
    "    'x'], batch_size=1, num_workers=0, shuffle=False)\n",
    "\n",
    "itr = iter(loader)\n",
    "batch = next(itr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24fab957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'outer_point', 'pos': array([-5.06972683, -3.64619632])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Graph[0].nodes[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fbd46e11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T05:27:03.030917Z",
     "iopub.status.busy": "2024-04-17T05:27:03.030599Z",
     "iopub.status.idle": "2024-04-17T05:27:14.170387Z",
     "shell.execute_reply": "2024-04-17T05:27:14.169567Z",
     "shell.execute_reply.started": "2024-04-17T05:27:03.030902Z"
    },
    "ExecuteTime": {
     "end_time": "2024-04-23T20:16:18.518491900Z",
     "start_time": "2024-04-23T20:16:18.209859900Z"
    }
   },
   "outputs": [],
   "source": [
    "import mpld3\n",
    "import numpy as np\n",
    "NUMPY_RANDOM = np.random.default_rng()\n",
    "\n",
    "\n",
    "class LateInitColorPalette:\n",
    "    \"\"\"\n",
    "        Класс создающий ссылки на цвета, количество которых заранее неизвестно\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.colors_list = []\n",
    "\n",
    "    def create_color(self):\n",
    "        \"\"\"\n",
    "            Создание словаря, который будет содержать цвет, добавление в список и возвращение ссылки на него\n",
    "        \"\"\"\n",
    "        dict_object = {}\n",
    "        self.colors_list.append(dict_object)\n",
    "        return dict_object\n",
    "\n",
    "    def init_colors(self):\n",
    "        \"\"\"\n",
    "            Вычисление цветов\n",
    "        \"\"\"\n",
    "        cmap = plt.cm.gist_rainbow\n",
    "        # создание равномерно расспределенной цветовой палитры\n",
    "        norm = colors.Normalize(vmin=0.0, vmax=float(len(self.colors_list)))\n",
    "        # создание списка цветов rgb в диапазоне 0.0-1.0\n",
    "        colors_list_rgb_0_1 = [\n",
    "            cmap(norm(float(e))) for e in range(len(self.colors_list))\n",
    "        ]\n",
    "        for i in range(len(self.colors_list)):\n",
    "            self.colors_list[i].update({\"rgb_1\": colors_list_rgb_0_1[i]})\n",
    "\n",
    "\n",
    "def convert_to_readable(value):\n",
    "    \"\"\"\n",
    "        Замена длинных значений (списков, массивов) на знаки\n",
    "        args:\n",
    "            value - любой объект\n",
    "        returns:\n",
    "            если не содердит много информации, то value,\n",
    "            иначе знаки \"<>\"\n",
    "    \"\"\"\n",
    "    replacement_str = \"<>\"\n",
    "    if type(value) == float:\n",
    "        value = replacement_str\n",
    "    if type(value) == list:\n",
    "        if len(value) > 5:\n",
    "            value = replacement_str\n",
    "    if type(value) == np.ndarray:\n",
    "        value = replacement_str\n",
    "\n",
    "    return value\n",
    "\n",
    "\n",
    "def plot_sg(g, add_border=True):\n",
    "    \"\"\"\n",
    "        Отрисовка графа.\n",
    "        Кроме исходного графа к нему добавляются узлы и ребра границ между помещениями\n",
    "        хранящиется в свойствах некоторых ребер\n",
    "        args:\n",
    "            d:nx.DiGraph - граф для отображения\n",
    "        returns:\n",
    "            None\n",
    "    \"\"\"\n",
    "    # инициализация переменных\n",
    "    g = nx.DiGraph(g)\n",
    "    colors_palette = LateInitColorPalette()\n",
    "    prop_color_dict = {}\n",
    "    plt.figure(1, figsize=(16, 14), dpi=650)\n",
    "    edges_color = {}\n",
    "    bounds = []\n",
    "    visible_edges_attrs = {}\n",
    "    visible_edges_attrs_0 = {}\n",
    "    visible_edges_attrs_1 = {}\n",
    "\n",
    "    # объединение свойств граней со свойствами исходного узла ребра,\n",
    "    # записываются в свойство ребра\n",
    "\n",
    "    # итерация по граням\n",
    "    nodes_to_hide = set()\n",
    "    edges_to_hide = []\n",
    "    for u, v, a in g.edges(data=True):\n",
    "        to_remove = False\n",
    "        if g.nodes[u].get('type', '') == 'targ_node':\n",
    "            if g.nodes[u].get('targ_pos') is None:\n",
    "                to_remove = True\n",
    "                nodes_to_hide.add(u)\n",
    "        if g.nodes[v].get('type', '') == 'targ_node':\n",
    "            if g.nodes[v].get('targ_pos') is None:\n",
    "                to_remove = True\n",
    "                edges_to_hide.append((u, v))\n",
    "                nodes_to_hide.add(v)\n",
    "        if not to_remove:\n",
    "            edge_attr = {}\n",
    "            edge_attr.update(a)\n",
    "\n",
    "            # свойства исходного узла\n",
    "            for k, vl in g.nodes[u].items():\n",
    "                vl = convert_to_readable(vl)\n",
    "                edge_attr.update({k + \"#\": vl})\n",
    "\n",
    "            # свойства грани\n",
    "            for k, vl in a.items():\n",
    "                edge_attr[k] = convert_to_readable(vl)\n",
    "\n",
    "                # отдельная запсиь в спислк границ\n",
    "                if add_border:\n",
    "                    if k == \"border\":\n",
    "                        bounds.append(vl)\n",
    "\n",
    "            # добавление в отображаемые свойства\n",
    "            visible_edges_attrs.update({(u, v): edge_attr})\n",
    "\n",
    "            # назначение ссылки на цвет\n",
    "            prop_color_dict[str(visible_edges_attrs[(u, v)])] = prop_color_dict.get(\n",
    "                str(visible_edges_attrs[(u, v)]), None\n",
    "            )\n",
    "            if prop_color_dict[str(visible_edges_attrs[(u, v)])] is None:\n",
    "                prop_color_dict[str(visible_edges_attrs[(u, v)])] = (\n",
    "                    colors_palette.create_color()\n",
    "                )\n",
    "            edge_attr.update(\n",
    "                {\"color\": prop_color_dict[str(visible_edges_attrs[(u, v)])]})\n",
    "            if u < v:\n",
    "                visible_edges_attrs_0[(u, v)] = visible_edges_attrs[(u, v)]\n",
    "            else:\n",
    "                visible_edges_attrs_1[(u, v)] = visible_edges_attrs[(u, v)]\n",
    "\n",
    "    # удаление скрываемых ребер\n",
    "    for r in edges_to_hide:\n",
    "        g.remove_edge(*r)\n",
    "    for r in nodes_to_hide:\n",
    "        g.remove_node(r)\n",
    "    # добавление узлов и ребер границ\n",
    "    for b in bounds:\n",
    "        for i in range(1, b.shape[0]):\n",
    "\n",
    "            prev_node = str(b[i - 1].tolist())\n",
    "            cur_node = str(b[i].tolist())\n",
    "\n",
    "            g.add_node(prev_node, **{\"pos\": b[i - 1]})\n",
    "            g.add_node(cur_node, **{\"pos\": b[i]})\n",
    "            g.add_edge(prev_node, cur_node)\n",
    "\n",
    "    # задание позиций со случайным смещением, для визуализации совпадающих узлов\n",
    "    pos = {\n",
    "        node_name: np.array(node_pos) + (NUMPY_RANDOM.random(2) - 0.5) * 0.01\n",
    "        for node_name, node_pos in nx.get_node_attributes(g, \"pos\").items()\n",
    "    }\n",
    "    pos2 = {\n",
    "        node_name: np.array(node_pos) + np.array([0.01, 0.01])\n",
    "        for node_name, node_pos in pos.items()\n",
    "    }\n",
    "    for n in pos.keys():\n",
    "        pos[n] = pos[n] + g.nodes[n].get(\"target_pos\", np.array([0.0, 0.0]))\n",
    "\n",
    "    # запись меток узлов\n",
    "    labels = {}\n",
    "    for n, d in g.nodes(data=True):\n",
    "        labels[n] = f\"{n}:\"\n",
    "        for k, v in d.items():\n",
    "            v = convert_to_readable(v)\n",
    "            labels[n] = labels[n] + f\" {k}:{v} |\"\n",
    "    colors_palette.init_colors()\n",
    "\n",
    "    # запст цветов\n",
    "    edges_color = [v[\"color\"][\"rgb_1\"] for k, v in visible_edges_attrs.items()]\n",
    "\n",
    "    for k, v in visible_edges_attrs.items():\n",
    "        dct = visible_edges_attrs[k]\n",
    "        del dct[\"color\"]\n",
    "\n",
    "    for k in prop_color_dict.keys():\n",
    "        print(k)\n",
    "\n",
    "    nx.draw(g, pos, node_size=2, arrowsize=1,\n",
    "            font_size=0, edge_color=edges_color)\n",
    "    nx.draw_networkx_labels(g, pos=pos, labels=labels, font_size=1)\n",
    "    nx.draw_networkx_edge_labels(\n",
    "        g, pos, edge_labels=visible_edges_attrs_0, font_size=1)\n",
    "    nx.draw_networkx_edge_labels(\n",
    "        g, pos2, edge_labels=visible_edges_attrs_1, font_size=1)\n",
    "    plt.gca().set_aspect(\"equal\")\n",
    "    # mpld3.show()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_sg(augment_graph(Graph_train[0]),add_border=False)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "raw",
   "id": "cf600d75",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "\n",
    "plot_sg(augment_graph(Graph_train[0]),add_border=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dab1399d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T00:02:24.929340Z",
     "iopub.status.busy": "2024-04-17T00:02:24.929140Z",
     "iopub.status.idle": "2024-04-17T00:02:24.932581Z",
     "shell.execute_reply": "2024-04-17T00:02:24.932136Z",
     "shell.execute_reply.started": "2024-04-17T00:02:24.929321Z"
    },
    "ExecuteTime": {
     "end_time": "2024-04-23T20:16:26.344099600Z",
     "start_time": "2024-04-23T20:16:26.339592800Z"
    }
   },
   "outputs": [],
   "source": [
    "def draw_edges(edges_tns, pos, secondary_pos=None):\n",
    "    \"\"\"\n",
    "        Отображение графа\n",
    "        args:\n",
    "            edges_tns:torch.Tensor - индексы ребер графа (2xN),\n",
    "            pos:torch.Tensor - позиции узлов графа (1хM),\n",
    "            secondary_pos:torch.Tensor - целевые позиции узлов графа (1хM),\n",
    "        returns:\n",
    "            None\n",
    "    \"\"\"\n",
    "\n",
    "    for e in range(edges_tns.shape[1]):\n",
    "        \n",
    "        i = edges_tns[0, e]\n",
    "        j = edges_tns[1, e]\n",
    "        pos_i = pos[i]\n",
    "        pos_j = pos[j]\n",
    "        if not secondary_pos is None:\n",
    "            pos_i = pos_i + secondary_pos[i][:2]\n",
    "            pos_j = pos_j + secondary_pos[j][:2]\n",
    "        vec = pos_j - pos_i\n",
    "        vec = vec * 0.8\n",
    "        pos_i_sh = pos_i + vec\n",
    "        plt.plot([float(pos_i[0]), float(pos_j[0])],\n",
    "                 [float(pos_i[1]), float(pos_j[1])])\n",
    "        plt.plot([float(pos_i_sh[0]), float(pos_j[0])], [\n",
    "                 float(pos_i_sh[1]), float(pos_j[1])], linewidth=4)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d506062b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T05:06:11.285520Z",
     "iopub.status.busy": "2024-04-17T05:06:11.285020Z",
     "iopub.status.idle": "2024-04-17T05:06:15.725358Z",
     "shell.execute_reply": "2024-04-17T05:06:15.724867Z",
     "shell.execute_reply.started": "2024-04-17T05:06:11.285505Z"
    },
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "plt.figure(1, figsize=(10, 10))\n",
    "draw_edges(batch.edge_index_line,batch.pos)\n",
    "#draw_edges(batch.edge_index_targ_connection,batch.pos,batch.targ)\n",
    "#draw_edges(batch.edge_index_targ_borders,batch.pos,batch.targ)\n",
    "draw_edges(batch.edge_index_targ_node_edge_0,batch.pos,batch.feats_targ)\n",
    "draw_edges(batch.edge_index_targ_node_edge_1,batch.pos,batch.feats_targ)\n",
    "draw_edges(batch.edge_index_targ_node_edge_2,batch.pos,batch.feats_targ)\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ab786d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T20:16:29.979861400Z",
     "start_time": "2024-04-23T20:16:29.962619Z"
    }
   },
   "outputs": [],
   "source": [
    "def draw_edges_color(edges_tns, pos, secondary_pos=None, feats=None):\n",
    "    \"\"\"\n",
    "        Отображение графа расцвеченого по сочитаниям фичей ребер\n",
    "        args:\n",
    "            edges_tns:torch.Tensor - индексы ребер графа (2xN),\n",
    "            pos:torch.Tensor - позиции узлов графа (1хM),\n",
    "            secondary_pos:torch.Tensor - целевые позиции узлов графа (1хM),\n",
    "            feats:torch.Tensor - фичи ребер (1хN),\n",
    "        returns:\n",
    "            None\n",
    "    \"\"\"\n",
    "    colors_palette = LateInitColorPalette()\n",
    "    prop_color_dict = {}\n",
    "    for e in range(edges_tns.shape[1]):\n",
    "        edge_feats = str((feats[e] != 0.0).tolist())\n",
    "        prop_color_dict[edge_feats] = prop_color_dict.get(\n",
    "            edge_feats, colors_palette.create_color())\n",
    "\n",
    "    colors_palette.init_colors()\n",
    "    for e in range(edges_tns.shape[1]):\n",
    "        edge_feats = str((feats[e] != 0.0).tolist())\n",
    "        prop_color_dict[edge_feats][\"lines\"] = []\n",
    "\n",
    "    for e in range(edges_tns.shape[1]):\n",
    "\n",
    "        i = edges_tns[0, e]\n",
    "        j = edges_tns[1, e]\n",
    "        pos_i = pos[i]\n",
    "        pos_j = pos[j]\n",
    "        if not secondary_pos is None:\n",
    "            pos_i = pos_i + secondary_pos[i][:2]\n",
    "            pos_j = pos_j + secondary_pos[j][:2]\n",
    "        vec = pos_j - pos_i\n",
    "        vec = vec * 0.9\n",
    "        pos_i_sh = pos_i + vec\n",
    "\n",
    "        edge_feats = str((feats[e] != 0.0).tolist())\n",
    "        prop_color_dict[edge_feats][\"lines\"].append(\n",
    "            [[float(pos_i[0]), float(pos_j[0])], [float(pos_i[1]), float(pos_j[1])]])\n",
    "        # plt.plot([float(pos_i[0]),float(pos_j[0])],[float(pos_i[1]),float(pos_j[1])],color=prop_color_dict[edge_feats][\"rgb_1\"])\n",
    "        # plt.plot([float(pos_i_sh[0]),float(pos_j[0])],[float(pos_i_sh[1]),float(pos_j[1])],color=prop_color_dict[edge_feats][\"rgb_1\"],linewidth = 4)\n",
    "        # if float(pos_i[1])<-8:\n",
    "        #    stop()\n",
    "    for edge_feats in prop_color_dict.keys():\n",
    "        for line in prop_color_dict[edge_feats][\"lines\"]:\n",
    "            plt.plot(*line, color=prop_color_dict[edge_feats][\"rgb_1\"])\n",
    "\n",
    "        plt.gca().set_aspect(\"equal\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "61c6a1c2",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "\n",
    "plt.figure(1, figsize=(10, 10))\n",
    "#draw_edges(batch.edge_index_line,batch.pos)\n",
    "#draw_edges(batch.edge_index_targ_connection,batch.pos,batch.targ)\n",
    "#draw_edges(batch.edge_index_targ_borders,batch.pos,batch.targ)\n",
    "draw_edges_color(batch.edge_index_first_graph,batch.pos,batch.feats_targ,batch.edge_feats_first_graph)\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dddf89f2",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "plt.figure(1, figsize=(10, 10))\n",
    "draw_edges(batch.edge_index_line,batch.pos)\n",
    "#draw_edges(batch.edge_index_targ_connection,batch.pos,batch.targ)\n",
    "#draw_edges(batch.edge_index_targ_borders,batch.pos,batch.targ)\n",
    "#draw_edges(batch.edge_index_targ_all_btw_areas,batch.pos,batch.targ)\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f62f94f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T00:02:27.402065Z",
     "iopub.status.busy": "2024-04-17T00:02:27.401923Z",
     "iopub.status.idle": "2024-04-17T00:02:27.405137Z",
     "shell.execute_reply": "2024-04-17T00:02:27.404830Z",
     "shell.execute_reply.started": "2024-04-17T00:02:27.402051Z"
    },
    "ExecuteTime": {
     "end_time": "2024-04-23T20:16:32.383362300Z",
     "start_time": "2024-04-23T20:16:32.375357900Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "75f9c2d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T00:02:27.405730Z",
     "iopub.status.busy": "2024-04-17T00:02:27.405616Z",
     "iopub.status.idle": "2024-04-17T00:02:27.412063Z",
     "shell.execute_reply": "2024-04-17T00:02:27.411451Z",
     "shell.execute_reply.started": "2024-04-17T00:02:27.405718Z"
    },
    "ExecuteTime": {
     "end_time": "2024-04-23T20:16:34.381878200Z",
     "start_time": "2024-04-23T20:16:34.300775500Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(2)\n",
    "torch.random.manual_seed(85)\n",
    "\n",
    "\n",
    "def repeat_by_count(coords):\n",
    "    \"\"\"\n",
    "    преобразование массива длинной N в матрицу NxN путем повторения массива\n",
    "    args:\n",
    "        coords:numpy.array - массив координат\n",
    "    returns:\n",
    "        матрица координат\n",
    "    \"\"\"\n",
    "    points_count = coords.shape[0]\n",
    "    return coords[None, :, :].repeat((points_count, 1, 1))\n",
    "\n",
    "\n",
    "def calc_len(tns):\n",
    "    \"\"\"\n",
    "    подсчет длины каждого вектора в матрице\n",
    "    args:\n",
    "        tns: torch.tensor Nx2\n",
    "    returns:\n",
    "        torch.tensor Nx2\n",
    "    \"\"\"\n",
    "    return tns.pow(2).sum(1).pow(0.5).unsqueeze(1)\n",
    "\n",
    "\n",
    "def poly_area(coords):\n",
    "    \"\"\"\n",
    "    площадь полигона\n",
    "    args:\n",
    "        coords: torch.tensor Nx2\n",
    "    returns:\n",
    "        torch.float32\n",
    "    \"\"\"\n",
    "    x, y = coords[:, 0], coords[:, 1]\n",
    "    return 0.5 * torch.abs(\n",
    "        torch.dot(x, torch.roll(y, 1)) - torch.dot(y, torch.roll(x, 1))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "95a808ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T00:02:27.412982Z",
     "iopub.status.busy": "2024-04-17T00:02:27.412720Z",
     "iopub.status.idle": "2024-04-17T00:02:27.416554Z",
     "shell.execute_reply": "2024-04-17T00:02:27.416174Z",
     "shell.execute_reply.started": "2024-04-17T00:02:27.412963Z"
    },
    "ExecuteTime": {
     "end_time": "2024-04-23T20:16:35.253125400Z",
     "start_time": "2024-04-23T20:16:35.242105100Z"
    }
   },
   "outputs": [],
   "source": [
    "class ContourVectorLayer(MessagePassing):\n",
    "    \"\"\"\n",
    "        Фиктивный слой для расчета векторов,\n",
    "        собственных весов и обучения нет\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # Аггрегация не используется, оставлено для совместимости\n",
    "        super().__init__(aggr='max')\n",
    "\n",
    "    def forward(self,\n",
    "                h: Tensor,\n",
    "                pos: Tensor,\n",
    "                edge_index: Tensor,\n",
    "                ) -> Tensor:\n",
    "        # Распространиене градиента\n",
    "        return self.propagate(edge_index, h=h, pos=pos)\n",
    "\n",
    "    def message(self,\n",
    "                h_j: Tensor,\n",
    "                pos_j: Tensor,\n",
    "                pos_i: Tensor,\n",
    "                ) -> Tensor:\n",
    "        # h_j: Фичи соседей [num_edges, in_channels]\n",
    "        # pos_j: Положение соседей [num_edges, 3]\n",
    "        # pos_i: Положение центрального узла [num_edges, 3]\n",
    "\n",
    "        edge_feat = pos_j - pos_i\n",
    "        return edge_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "92c6b920",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T00:02:27.419091Z",
     "iopub.status.busy": "2024-04-17T00:02:27.418832Z",
     "iopub.status.idle": "2024-04-17T00:02:27.592190Z",
     "shell.execute_reply": "2024-04-17T00:02:27.591755Z",
     "shell.execute_reply.started": "2024-04-17T00:02:27.419076Z"
    },
    "ExecuteTime": {
     "end_time": "2024-04-23T20:16:36.471023100Z",
     "start_time": "2024-04-23T20:16:36.453171400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Модель\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    \"\"\"\n",
    "        Класс графовой нейронной сети.\n",
    "        На вход модели подается следующий граф планировки: \n",
    "            x - кодирование признаки узлв (ohe)\n",
    "            pos - позиции узлов,\n",
    "            debug_sg_ind - индекс графа (для отладки),\n",
    "\n",
    "            edge_index_line - наружный контур,\n",
    "            edge_index_from_line_to_cnt - все связи центра с наружным контуром,\n",
    "            edge_index_aprt_cnt_to_areas - все связи центра планировки с центрами помещений,\n",
    "            edge_index_targ_connection - все связи аомещений между собой,\n",
    "\n",
    "        на выходе:\n",
    "            матрица контуров NxMAX_POINTSx2,\n",
    "            матрица весов узлв Nx16\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.points = MAX_POINTS\n",
    "        # слой расчета векторов линий направленного графа\n",
    "        self.cvc = ContourVectorLayer()\n",
    "        # слои расчета внутренних осей\n",
    "        # self.gatconv_upsc = GATConv(2, 4, add_self_loops=True)\n",
    "        # self.gatconv_inw = GATConv(4, 4, add_self_loops=True)\n",
    "        # self.gatconv_outw = GATConv(4, 4, add_self_loops=True)\n",
    "        # self.gatconv_rot1 = GATConv(4, 4, add_self_loops=True)\n",
    "        # self.gatconv_rot2 = GATConv(4, 4, add_self_loops=True)\n",
    "        # self.gatconv_rot3 = GATConv(4, 4, add_self_loops=True)\n",
    "        # self.gatconv_rot4 = GATConv(4, 4, add_self_loops=True)\n",
    "        # self.gatconv_center_rot_0 = GATConv(4, 2, add_self_loops=False)\n",
    "        # self.gatconv_center_rot_1 = GATConv(2, 2, add_self_loops=False)\n",
    "\n",
    "        # количество нейронов\n",
    "        self.entry_features = 256\n",
    "\n",
    "        self.geom_and_feats_to_entry_features = GATConv(4 + TOTAL_CLASSES,\n",
    "                                                        self.entry_features, add_self_loops=True)\n",
    "        self.to_logical_to_entry_features = GATConv(31,\n",
    "                                                    self.entry_features, add_self_loops=True)\n",
    "        # количество слоев\n",
    "\n",
    "        self.l0 = GATConv(\n",
    "            self.entry_features*5, 5, add_self_loops=True)\n",
    "        self.l1 = GATConv(\n",
    "            self.entry_features*5, 5, add_self_loops=True)\n",
    "        self.l2 = GATConv(\n",
    "            self.entry_features*5, 5, add_self_loops=True)\n",
    "        # инициализация слоев\n",
    "        self.mlayers = 1\n",
    "        self.heads_count = 1\n",
    "        self.gatc_array = nn.ModuleList([GATConv(\n",
    "            self.entry_features, self.entry_features-4, add_self_loops=True, heads=self.heads_count) for i in range(self.mlayers)])\n",
    "\n",
    "        # слой преобразования весов в одну из координат\n",
    "        self.pred_final = GATConv(self.entry_features, self.entry_features, add_self_loops=False,heads = 5)\n",
    "\n",
    "        self.final = GATConv(self.entry_features*5, 5, add_self_loops=True)\n",
    "\n",
    "\n",
    "    def forward(self, data):\n",
    "\n",
    "        dbg_out = {}\n",
    "        x = data.x\n",
    "        pos = data.pos\n",
    "\n",
    "        edge_index_from_center_to_all_nodes = data.edge_index_from_center_to_all_nodes\n",
    "        edge_index_first_graph = data.edge_index_first_graph\n",
    "        edge_feats_first_graph = data.edge_feats_first_graph\n",
    "        edge_index_line = data.edge_index_line\n",
    "        edge_index_from_line_to_cnt = data.edge_index_from_line_to_cnt\n",
    "        edge_index_targ_node_edge_0 = data.edge_index_targ_node_edge_0\n",
    "        edge_index_targ_node_edge_1 = data.edge_index_targ_node_edge_1\n",
    "        edge_index_targ_node_edge_2 = data.edge_index_targ_node_edge_2\n",
    "\n",
    "        length_tang = calc_len(\n",
    "            self.cvc(None, pos=pos, edge_index=edge_index_line))\n",
    "        # получение векторов от центра к наружному контуру\n",
    "        vectors_radial_out = self.cvc(\n",
    "            None, pos=pos, edge_index=rev_edges(edge_index_from_line_to_cnt))\n",
    "        # получение длин от центра к наружному контуру\n",
    "        length_radial = calc_len(vectors_radial_out)\n",
    "\n",
    "        if False:\n",
    "            # 1. вычисление внутренней ориентации фигуры\n",
    "            # получение длин между точками наружного контура\n",
    "\n",
    "            # конкатенация\n",
    "            all_nodes_feats = torch.cat((length_tang,\n",
    "                                        length_radial,\n",
    "                                         ), dim=1)\n",
    "\n",
    "            all_nodes_feats = all_nodes_feats\n",
    "\n",
    "            # проходы вдоль наружного контура, внутрь и наружу 2 раза\n",
    "            all_nodes_feats = self.gatconv_upsc(\n",
    "                all_nodes_feats, edge_index_line)\n",
    "            all_nodes_feats = self.gatconv_inw(\n",
    "                all_nodes_feats, edge_index_from_line_to_cnt)\n",
    "            all_nodes_feats = self.gatconv_outw(\n",
    "                all_nodes_feats, rev_edges(edge_index_from_line_to_cnt))\n",
    "            all_nodes_feats = self.gatconv_rot1(\n",
    "                all_nodes_feats, edge_index_line)\n",
    "            all_nodes_feats = self.gatconv_rot2(\n",
    "                all_nodes_feats, edge_index_from_line_to_cnt)\n",
    "            all_nodes_feats = self.gatconv_rot3(\n",
    "                all_nodes_feats, rev_edges(edge_index_from_line_to_cnt))\n",
    "            all_nodes_feats = self.gatconv_rot4(\n",
    "                all_nodes_feats, edge_index_line)\n",
    "\n",
    "            # массив, из фичей, на основании которого считается внутренняя ориентация\n",
    "            all_nodes_feats = self.gatconv_center_rot_0(\n",
    "                all_nodes_feats, edge_index_from_line_to_cnt)\n",
    "\n",
    "            # распространение на все узлы\n",
    "            rot_matr_vecs = self.gatconv_center_rot_1(\n",
    "                all_nodes_feats, edge_index_from_center_to_all_nodes)\n",
    "\n",
    "            rot_matr_vecs_lengthes = rot_matr_vecs.pow(\n",
    "                2).sum(1).pow(0.5) + 0.000001\n",
    "            # нормализация\n",
    "            rot_matr_vecs = rot_matr_vecs/rot_matr_vecs_lengthes[:, None]\n",
    "\n",
    "            rot_matr_vecs = torch.cat(\n",
    "                (rot_matr_vecs, -rot_matr_vecs[:, 1:2], rot_matr_vecs[:, 0:1]), dim=1)\n",
    "\n",
    "            nodes_rot_matr = rot_matr_vecs.view(-1, 2, 2)\n",
    "            # поворот всех коодинат на по этим векторам\n",
    "            pos_rotated = torch.matmul(\n",
    "                pos[:, None, :], nodes_rot_matr)[:, 0, :]\n",
    "\n",
    "        # room_features = x\n",
    "\n",
    "        # 2. непосредственно обучение\n",
    "        # конкатенация всех фичей и координат\n",
    "\n",
    "        pos_features = torch.cat((pos,\n",
    "                                  length_tang,\n",
    "                                  length_radial,\n",
    "                                  x), dim=1)\n",
    "        # all_edges = add_reverse_dir(torch.cat(\n",
    "        #    (edge_index_line, edge_index_from_line_to_cnt, edge_index_targ_connection, edge_index_aprt_cnt_to_areas), dim=1))\n",
    "\n",
    "        all_nodes_feats = self.geom_and_feats_to_entry_features(\n",
    "            pos_features, edge_index_first_graph)\n",
    "\n",
    "        # i = 0\n",
    "        split_part = 50  # часть фичей которая не проходи через Relu\n",
    "        # (там сохраняются координаты, которые могут быть отрицательнами)\n",
    "\n",
    "        # все вектора ребер\n",
    "\n",
    "        # all_edges_vects = edge_feats_first_graph[:, 1:3]\n",
    "        # поворот всех векторов ребер в соответствии с матрицей поворта начального узла вектора\n",
    "        #        first_praph_start_indices = edge_index_first_graph[0].detach()\n",
    "        #        first_praph_end_indices = edge_index_first_graph[1].detach()\n",
    "#\n",
    "#\n",
    "        # rotation_matr_gather_indices = first_praph_start_indices[:,None,None].repeat((1,2,2))\n",
    "        #\n",
    "        #        first_praph_start_pos = torch.gather(pos_rotated,0,first_praph_start_indices[:,None].repeat((1,2))).detach()\n",
    "        #        first_praph_end_pos = torch.gather(pos_rotated,0,first_praph_end_indices[:,None].repeat((1,2))).detach()\n",
    "        # print('rminds\\n',rminds)\n",
    "#\n",
    "        # rot_matr_4_all_edges_vects = torch.gather(nodes_rot_matr,0,rotation_matr_gather_indices)\n",
    "        # rot_matr_4_all_edges_vects = rot_matr_4_all_edges_vects.detach()\n",
    "        # print('rot_matr_4_all_edges_vects\\n',rot_matr_4_all_edges_vects)\n",
    "        # print('all_edges_vectsstart\\n',edge_feats_first_graph[:, 1:3])\n",
    "        #        first_praph_vects = first_praph_end_pos - first_praph_start_pos\n",
    "        # first_praph_lengthes = first_praph_vects.pow(2).sum(1).pow(0.5)\n",
    "        #        edge_feats_first_graph = torch.cat((edge_feats_first_graph,\n",
    "        #                                    first_praph_vects),dim = 1)\n",
    "        # edge_feats_first_graph[:, 1:3] = torch.matmul(edge_feats_first_graph[:, 1:3][:, None, :], rot_matr_4_all_edges_vects)[:, 0, :]\n",
    "        # print('all_edges_vects\\n',edge_feats_first_graph[:, 1:3])\n",
    "        # edge_feats_first_graph[:, 1:3] = all_edges_vects\n",
    "\n",
    "        # del all_edges_vects\n",
    "\n",
    "        # циклы распространения градиентов по узлам\n",
    "        for i in range(self.mlayers):\n",
    "\n",
    "            all_nodes_feats = self.gatc_array[i](\n",
    "                all_nodes_feats, edge_index_first_graph, edge_attr=edge_feats_first_graph) + all_nodes_feats[:,4:]\n",
    "            # all_nodes_feats = all_nodes_feats.view(all_nodes_feats.shape[0],self.entry_features-4,self.heads_count).median(2)[0]\n",
    "\n",
    "            # i = i + 1\n",
    "            # добавление координат\n",
    "            all_nodes_feats = torch.cat((pos,\n",
    "                                         length_tang,\n",
    "                                         length_radial,\n",
    "                                         all_nodes_feats), dim=1)\n",
    "            # частичное применение активации\n",
    "            all_nodes_feats[:, split_part:] = nn.ReLU()(\n",
    "                all_nodes_feats[:, split_part:])\n",
    "\n",
    "        # частичное применение активации\n",
    "        all_nodes_feats[:, split_part:] = nn.Sigmoid()(\n",
    "            all_nodes_feats[:, split_part:])\n",
    "        \n",
    "        \n",
    "        all_nodes_feats = self.pred_final(all_nodes_feats, edge_index_first_graph, edge_attr=edge_feats_first_graph)\n",
    "        pred = self.final(all_nodes_feats, edge_index_first_graph, edge_attr=edge_feats_first_graph) \\\n",
    "            + self.l0(all_nodes_feats, edge_index_targ_node_edge_0) \\\n",
    "            + self.l1(all_nodes_feats, edge_index_targ_node_edge_1) \\\n",
    "            + self.l2(all_nodes_feats, edge_index_targ_node_edge_2)\n",
    "\n",
    "        # обратный поворот в реальные координаты по матрице поворота\n",
    "        # rot_matr_vecs[:, 1] = -rot_matr_vecs[:, 1]\n",
    "        # rot_matr_vecs[:, 2] = -rot_matr_vecs[:, 2]\n",
    "        # nodes_rot_matr = rot_matr_vecs.view(-1, 2, 2)\n",
    "#\n",
    "        #\n",
    "        # pred_pos = pred[:, :2]\n",
    "        # pred_pos = torch.matmul(pred_pos[:, None, :], nodes_rot_matr)[:, 0, :]\n",
    "        # pred = torch.cat((pred_pos, pred[:, 2:]), dim=1)\n",
    "\n",
    "        return pred  # ,nodes_rot_matr"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a0a7d947",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# test\n",
    "loader = DataLoader(data_gen, follow_batch=[\n",
    "                    'x'], batch_size=1, num_workers=0, shuffle=False)\n",
    "model = GCN()\n",
    "model = model.to(CUDA_0)\n",
    "batch = next(iter(loader))\n",
    "batch = batch.to(CUDA_0)\n",
    "out = model(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9a42869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([213, 252])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros([213, 1260]).view(213, 252, 5).median(2)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b06dbebb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T00:02:36.127990Z",
     "iopub.status.busy": "2024-04-17T00:02:36.127329Z",
     "iopub.status.idle": "2024-04-17T00:02:36.131749Z",
     "shell.execute_reply": "2024-04-17T00:02:36.131352Z",
     "shell.execute_reply.started": "2024-04-17T00:02:36.127972Z"
    },
    "ExecuteTime": {
     "end_time": "2024-04-23T20:16:57.144689400Z",
     "start_time": "2024-04-23T20:16:57.133181400Z"
    }
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"\n",
    "        Расчет среднего параметра\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "            Иницализация переменных\n",
    "        \"\"\"\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, error_sum, n=1):\n",
    "        \"\"\"\n",
    "            Обновление среднего значения \n",
    "        \"\"\"\n",
    "        self.val = error_sum\n",
    "        self.sum += error_sum\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dd440b1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T00:02:36.132526Z",
     "iopub.status.busy": "2024-04-17T00:02:36.132278Z",
     "iopub.status.idle": "2024-04-17T00:02:36.135541Z",
     "shell.execute_reply": "2024-04-17T00:02:36.135217Z",
     "shell.execute_reply.started": "2024-04-17T00:02:36.132512Z"
    },
    "ExecuteTime": {
     "end_time": "2024-04-23T20:16:58.442805600Z",
     "start_time": "2024-04-23T20:16:58.431298400Z"
    }
   },
   "outputs": [],
   "source": [
    "def edges_to_plt_lines(edges_tns, pos, secondary_pos=None):\n",
    "    \"\"\"\n",
    "        Преобразование индексов узлов и позиций в список для черчения в matplotlib\n",
    "        args:\n",
    "            edges_tns:torch.Tensor - индексы ребер графа (2xN),\n",
    "            pos:torch.Tensor - позиции узлов графа (1хM),\n",
    "            secondary_pos:torch.Tensor - целевые позиции узлов графа (1хM),\n",
    "        returns:\n",
    "            список кортежей линий для matplotlib\n",
    "    \"\"\"\n",
    "    lines_list = []\n",
    "\n",
    "    for e in range(edges_tns.shape[1]):\n",
    "        \n",
    "        i = edges_tns[0, e]\n",
    "        j = edges_tns[1, e]\n",
    "        # получени позиции\n",
    "        pos_i = pos[i]\n",
    "        pos_j = pos[j]\n",
    "        # сложение с целевой позицией\n",
    "        if not secondary_pos is None:\n",
    "            pos_i = pos_i + secondary_pos[i][:2]\n",
    "            pos_j = pos_j + secondary_pos[j][:2]\n",
    "        lines_list.extend([(float(pos_i[0]), float(pos_j[0])),\n",
    "                          (float(pos_i[1]), float(pos_j[1]))])\n",
    "    return lines_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f926b962",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T20:17:00.513187800Z",
     "start_time": "2024-04-23T20:17:00.501156Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_lr(optimizer, lr):\n",
    "    for g in optimizer.param_groups:\n",
    "        g['lr'] = lr\n",
    "\n",
    "\n",
    "def get_lr_0(optimizer):\n",
    "    for g in optimizer.param_groups:\n",
    "        return g['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "806c6b42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T20:17:01.100114Z",
     "start_time": "2024-04-23T20:17:01.088405100Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_checkpoint_and_vars(weights_pne=None, model=None, optimizer=None, **kwargs):\n",
    "\n",
    "    other_variables = {}\n",
    "    other_variables.update(kwargs)\n",
    "\n",
    "    checkpoint = {\n",
    "\n",
    "        'model': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'other_variables': other_variables}\n",
    "\n",
    "    torch.save(checkpoint, weights_pne)\n",
    "\n",
    "\n",
    "def load_checkpoint_and_vars(weights_pne,\n",
    "                             model,\n",
    "                             optimizer):\n",
    "    checkpoint = torch.load(weights_pne)\n",
    "    model.load_state_dict(checkpoint['model'], strict=False)\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    for state in optimizer.state.values():\n",
    "        for k, v in state.items():\n",
    "            if isinstance(v, torch.Tensor):\n",
    "                state[k] = v.to(CUDA_0)\n",
    "    for k, v in checkpoint.get('other_variables', {}).items():\n",
    "        print('loaded:', k)\n",
    "\n",
    "    globals().update(checkpoint.get('other_variables', {}))\n",
    "\n",
    "    print('weights loadad')\n",
    "\n",
    "    return (model,\n",
    "            optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2fc702",
   "metadata": {},
   "source": [
    "# Инициализауия обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a37374b",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# начальные параметры\n",
    "start_lr = 0.0005\n",
    "task_name = 'regression 3 pt ,batch 50 256 neurons lehgth loss noflip increse targ_egdes 1 layer'\n",
    "weights_pne = task_name + \"_best.pth\"\n",
    "batch_size = 100\n",
    "\n",
    "# вспомогательные переменные\n",
    "history_dict = {}\n",
    "watch_indices = [20, 165, 953,\n",
    "                 len(train_data) + 889,\n",
    "                 len(train_data) + 1129,\n",
    "                 len(train_data) + 2519]\n",
    "drawings = {}\n",
    "current_dict = {}\n",
    "prev_time = [0]\n",
    "last_saved_at = 0\n",
    "START_LOSS = 100500.0\n",
    "min_loss = START_LOSS\n",
    "\n",
    "\n",
    "model = GCN()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=start_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a86c8f92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T20:17:09.237275200Z",
     "start_time": "2024-04-23T20:17:09.209317400Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Neuro\\houseganpp-main\\env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 6 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "batch_size=5\n",
    "\n",
    "train_loader = DataLoader(DataGen(train_data), follow_batch=[\n",
    "    'x'], batch_size=batch_size, num_workers=10, shuffle=True)\n",
    "val_loader = DataLoader(DataGen(val_data), follow_batch=[\n",
    "    'x'], batch_size=batch_size, num_workers=10, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "89c71a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set_lr(optimizer,0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8acffda0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T20:17:15.299942200Z",
     "start_time": "2024-04-23T20:17:15.239461700Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "if os.path.isfile(weights_pne):\n",
    "\n",
    "    (model,\n",
    "     optimizer) = load_checkpoint_and_vars(weights_pne,\n",
    "                                           model,\n",
    "                                           optimizer)\n",
    "    current_dict['last_saved_at'] = last_saved_at\n",
    "else:\n",
    "\n",
    "    epoch = 0\n",
    "\n",
    "model = model.to(CUDA_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "32b88ce4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T20:17:22.222427100Z",
     "start_time": "2024-04-23T20:17:19.678206100Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from contextlib import nullcontext\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "\n",
    "tensorboard_writer = SummaryWriter('tensorboard_logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d7a3239e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CLEARML_WEB_HOST=http://clearml.smarthomecrafters.ai:8080\n",
      "env: CLEARML_API_HOST=http://clearml.smarthomecrafters.ai:8008\n",
      "env: CLEARML_FILES_HOST=http://clearml.smarthomecrafters.ai:8081\n",
      "env: CLEARML_API_ACCESS_KEY=ETRNXJ8DTDSGS3T4X0PK\n",
      "env: CLEARML_API_SECRET_KEY=WeNR0Mp5EGm7edR06J7YoOCNUGDNBlcEvd5ROHg14pU1Z6YXCK\n"
     ]
    }
   ],
   "source": [
    "%env CLEARML_WEB_HOST=http://clearml.smarthomecrafters.ai:8080\n",
    "%env CLEARML_API_HOST=http://clearml.smarthomecrafters.ai:8008\n",
    "%env CLEARML_FILES_HOST=http://clearml.smarthomecrafters.ai:8081\n",
    "%env CLEARML_API_ACCESS_KEY=ETRNXJ8DTDSGS3T4X0PK\n",
    "%env CLEARML_API_SECRET_KEY=WeNR0Mp5EGm7edR06J7YoOCNUGDNBlcEvd5ROHg14pU1Z6YXCK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a7b751a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=c574643434f24fca95a49f615d7dacd7\n",
      "2024-04-23 01:27:01,218 - clearml.Task - INFO - Storing jupyter notebook directly as code\n",
      "ClearML results page: http://clearml.smarthomecrafters.ai:8080/projects/8b1c9c083e6a4590a63098f125f27fae/experiments/c574643434f24fca95a49f615d7dacd7/output/log\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from clearml import Task\n",
    "task = Task.init(project_name='House planning', task_name=task_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "11fa210e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "# scheduler = ReduceLROnPlateau(optimizer, 'min')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b7f7cce9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T20:17:31.971701100Z",
     "start_time": "2024-04-23T20:17:31.958450300Z"
    }
   },
   "outputs": [],
   "source": [
    "set_lr(optimizer,0.0007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ea9f0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T00:03:30.765438Z",
     "iopub.status.busy": "2024-04-17T00:03:30.765107Z",
     "iopub.status.idle": "2024-04-17T01:53:53.520477Z",
     "shell.execute_reply": "2024-04-17T01:53:53.519732Z",
     "shell.execute_reply.started": "2024-04-17T00:03:30.765423Z"
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def filter_edges_by_inds(edges, inds):\n",
    "    \"\"\"\n",
    "        Фильтрация ребер по списку индексов\n",
    "\n",
    "    \"\"\"\n",
    "    msk = torch.isin(edges, inds).sum(0) > 0\n",
    "    return edges[:, msk]\n",
    "\n",
    "\n",
    "def train_val_epoch(model, loader, optimizer=None,\n",
    "                    todo_train=False,\n",
    "                    history_dict={},\n",
    "                    current_dict={},\n",
    "                    watch_indices=[],\n",
    "                    drawings={},\n",
    "                    epoch=0, prev_time=[0]):\n",
    "    \n",
    "    # условная инициализация пременных цикла обучения/валидации\n",
    "    if todo_train:\n",
    "        trvalstr = 'trainmodel'\n",
    "        assert not optimizer is None\n",
    "        with_cont = nullcontext\n",
    "        model.train()\n",
    "        current_dict['_epoch_start'] = time.time()\n",
    "    else:\n",
    "        trvalstr = 'val'\n",
    "        with_cont = torch.no_grad\n",
    "        model.eval()\n",
    "    # инициализация пременных цикла обучения/валидации\n",
    "    loss_avg = AverageMeter()\n",
    "    loss_geom_avg = AverageMeter()\n",
    "    loss_geom_length_avg = AverageMeter()\n",
    "    loss_feat_avg = AverageMeter()\n",
    "    loss_existence_avg = AverageMeter()\n",
    "\n",
    "    for batch_index, batch in enumerate(loader):\n",
    "        with with_cont():\n",
    "\n",
    "            pred = model(batch.to(CUDA_0))\n",
    "            # целевые фичи всех узлов\n",
    "            feats_targ = batch.feats_targ\n",
    "            # маска целевых узлов\n",
    "            targ_mask = feats_targ[:, 5] > 0.5\n",
    "            # предсказанные фичи всех целевых узлов\n",
    "            pred_masked = pred[targ_mask]\n",
    "            # целевые фичи всех целевых узлов\n",
    "            targ_masked = feats_targ[targ_mask]\n",
    "            # лосс наличия узла\n",
    "            loss_existence = (\n",
    "                pred_masked[:, 4:5] - targ_masked[:, 4:5]).pow(2).sum(1).mean(0) * 10.0\n",
    "            # маска существующих целевых узлов\n",
    "            targ_existed = targ_masked[:, 4] > 0.5\n",
    "\n",
    "            pred_masked_existed = pred_masked[targ_existed]\n",
    "            targ_masked_existed = targ_masked[targ_existed]\n",
    "            # геометрический лосс существующих целевых узлов\n",
    "            loss_geom = (\n",
    "                pred_masked_existed[:, :2] - targ_masked_existed[:, :2]).pow(2).sum(1).pow(1).mean(0)\n",
    "            # лосс фичей существующих целевых узлов\n",
    "            loss_feat = (\n",
    "                pred_masked_existed[:, 2:4] - targ_masked_existed[:, 2:4]).pow(2).sum(1).mean(0)\n",
    "\n",
    "            #btw_targ_node_start_indices = batch.edge_index_debug_btw_targ_node_edge[0]\n",
    "            #btw_targ_node_end_indices = batch.edge_index_debug_btw_targ_node_edge[1]\n",
    "\n",
    "            #btw_targ_node_targ_start_pos = torch.gather(\n",
    "            #    batch.feats_targ[:, :2], 0, btw_targ_node_start_indices[:, None].repeat((1, 2)))\n",
    "            #btw_targ_node_targ_end_pos = torch.gather(\n",
    "            #    batch.feats_targ[:, :2], 0, btw_targ_node_end_indices[:, None].repeat((1, 2)))\n",
    "#\n",
    "            #btw_targ_node_targ_vects = btw_targ_node_targ_end_pos - btw_targ_node_targ_start_pos\n",
    "            #btw_targ_node_targ_lengthes = btw_targ_node_targ_vects.pow(\n",
    "            #    2).sum(1).pow(0.5)\n",
    "\n",
    "            #btw_targ_node_pred_start_pos = torch.gather(\n",
    "            #    pred[:, :2], 0, btw_targ_node_start_indices[:, None].repeat((1, 2)))\n",
    "            #btw_targ_node_pred_end_pos = torch.gather(\n",
    "            #    pred[:, :2], 0, btw_targ_node_end_indices[:, None].repeat((1, 2)))\n",
    "#\n",
    "            #btw_targ_node_pred_vects = btw_targ_node_pred_end_pos - btw_targ_node_pred_start_pos\n",
    "            #btw_targ_node_pred_lengthes = btw_targ_node_pred_vects.pow(\n",
    "            #    2).sum(1).pow(0.5)\n",
    "\n",
    "            #loss_geom_length = (btw_targ_node_pred_lengthes -\n",
    "            #                    btw_targ_node_targ_lengthes).pow(2).mean()\n",
    "\n",
    "            # суммарный лосс\n",
    "            loss = loss_geom + loss_feat + loss_existence\n",
    "            for i in watch_indices:\n",
    "                watch_ind = i\n",
    "                if not todo_train:\n",
    "                    watch_ind = i - len(train_data)\n",
    "\n",
    "                # маска одной планировки\n",
    "                sample_msk = batch.debug_sg_ind == watch_ind\n",
    "                if sample_msk.sum() > 0:\n",
    "                    # придикт планировки\n",
    "                    pred_sample = pred[sample_msk]\n",
    "                    # ребра планировки\n",
    "                    graph_nodes = batch.edge_index_debug_all_node_indices[sample_msk]\n",
    "                    \n",
    "                    visible_pred_nodes_mask = pred_sample[:, 4] > 0.5\n",
    "                    # целевые узлы предсказаные как существующие\n",
    "                    visible_pred_nodes = graph_nodes[visible_pred_nodes_mask]\n",
    "\n",
    "                    # ребра наружного контура\n",
    "                    edge_index_line = filter_edges_by_inds(\n",
    "                        batch.edge_index_line, graph_nodes)\n",
    "                    \n",
    "                    # ребра между целевыми узлами заданными как существующие\n",
    "                    edge_index_debug_btw_targ_node_edge = filter_edges_by_inds(\n",
    "                        batch.edge_index_debug_btw_targ_node_edge, graph_nodes)\n",
    "\n",
    "                    # ребра между целевыми узлами предсказаными как существующие\n",
    "                    edge_index_btw_pred_node_edge = filter_edges_by_inds(\n",
    "                        batch.edge_index_debug_btw_targ_node_edge, visible_pred_nodes)\n",
    "\n",
    "                    # обратный поворот\n",
    "                    batch_pos_rotated = torch.matmul(\n",
    "                        batch.pos[:, None, :], batch.debug_rev_rot_matr)[:, 0, :]\n",
    "                    targ_rotated = torch.matmul(\n",
    "                        feats_targ[:, :2][:, None, :], batch.debug_rev_rot_matr)[:, 0, :]\n",
    "                    pred_rotated = torch.matmul(\n",
    "                        pred[:, :2][:, None, :], batch.debug_rev_rot_matr)[:, 0, :]\n",
    "                    \n",
    "                    # прееобразование в линии для черчения\n",
    "                    lines = edges_to_plt_lines(\n",
    "                        edge_index_line, batch_pos_rotated, targ_rotated)\n",
    "                    btw_targ_node_edges = edges_to_plt_lines(\n",
    "                        edge_index_debug_btw_targ_node_edge, batch_pos_rotated, targ_rotated)\n",
    "                    btw_pred_node_edges = edges_to_plt_lines(\n",
    "                        edge_index_btw_pred_node_edge, batch_pos_rotated, pred_rotated)\n",
    "\n",
    "                    # сохранение в словарь\n",
    "                    drawings[trvalstr + \" \" + str(watch_ind)] = {'lines': lines,\n",
    "                                                                 'btw_targ_node_edges': btw_targ_node_edges,\n",
    "                                                                 'btw_pred_node_edges': btw_pred_node_edges,\n",
    "                                                                 }\n",
    "\n",
    "            if todo_train:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            # запись лоссов\n",
    "            loss = loss.cpu().detach()\n",
    "            loss_geom = loss_geom.cpu().detach()\n",
    "            loss_feat = loss_feat.cpu().detach()\n",
    "            loss_existence = loss_existence.cpu().detach()\n",
    "            #loss_geom_length = loss_geom_length.cpu().detach()\n",
    "            pred_masked = pred_masked.cpu().detach()\n",
    "            loss_geom_avg.update(loss_geom)\n",
    "            #loss_geom_length_avg.update(loss_geom_length)\n",
    "            loss_feat_avg.update(loss_feat)\n",
    "            loss_existence_avg.update(loss_existence)\n",
    "\n",
    "            loss_avg.update(loss)\n",
    "\n",
    "            current_dict[trvalstr + ' loss'] = loss_avg.avg\n",
    "            current_dict[trvalstr + ' loss_geom'] = loss_geom_avg.avg\n",
    "            #current_dict[trvalstr + ' loss_geom_length'] = loss_geom_length_avg.avg\n",
    "            current_dict[trvalstr + ' loss_feat'] = loss_feat_avg.avg\n",
    "            current_dict[trvalstr + ' loss_existence'] = loss_existence_avg.avg\n",
    "            current_dict['lr'] = get_lr_0(optimizer)\n",
    "            current_dict['epoch'] = epoch\n",
    "            # clear_output(wait=True)\n",
    "            # for k,v in current_dict.items():\n",
    "            #    print(k,v)\n",
    "            # for k,v in drawings.items():\n",
    "            #    print(k)\n",
    "\n",
    "            # отображение\n",
    "            if time.time() - prev_time[0] > 20:\n",
    "                clear_output(wait=True)\n",
    "\n",
    "                # \n",
    "                for k, v in current_dict.items():\n",
    "                    if k[0] != \"_\":\n",
    "                        print(k, v)\n",
    "                for k, v in drawings.items():\n",
    "                    print(k)\n",
    "                    for type_, lines in v.items():\n",
    "                        plt.plot(*lines, c=colors_dict[type_])\n",
    "                    plt.gca().set_aspect(\"equal\")\n",
    "                    plt.show()\n",
    "\n",
    "                for k, v in history_dict.items():\n",
    "                    print(k)\n",
    "                    if k != \"epoch\" and k != \"min_loss\":\n",
    "                        plt.plot(v)\n",
    "                        plt.show()\n",
    "                prev_time[0] = time.time()\n",
    "\n",
    "                print(trvalstr + ' iter/total' +\n",
    "                      str(batch_index)+'/' + str(len(loader)))\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "###########################\n",
    "colors_dict = {'lines': 'r',\n",
    "               'btw_targ_node_edges': 'g',\n",
    "               'btw_pred_node_edges': 'b',\n",
    "               'orientation': 'black'}\n",
    "\n",
    "\n",
    "for e in range(100000):\n",
    "    print(epoch)\n",
    "\n",
    "    for train_step in range(2):\n",
    "\n",
    "        if train_step == 0:\n",
    "            todo_train = True\n",
    "            loader = train_loader\n",
    "        else:\n",
    "            todo_train = False\n",
    "            loader = val_loader\n",
    "\n",
    "        train_val_epoch(model, loader, optimizer=optimizer,\n",
    "                        todo_train=todo_train,\n",
    "                        history_dict=history_dict,\n",
    "                        current_dict=current_dict,\n",
    "                        watch_indices=watch_indices,\n",
    "                        drawings=drawings,\n",
    "                        epoch=epoch, prev_time=prev_time)\n",
    "\n",
    "    # расчет времени эпохи\n",
    "    if not current_dict.get('_epoch_start') is None:\n",
    "        current_dict['epoch_duration_minutes'] = round(\n",
    "                (time.time() - current_dict.get('_epoch_start'))/60.0, 3)\n",
    "        \n",
    "    # запись в историю\n",
    "    for k, v in current_dict.items():\n",
    "        if k[0] != \"_\":\n",
    "            history_dict[k] = history_dict.get(k, [])\n",
    "            history_dict[k].append(float(v))\n",
    "\n",
    "        tensorboard_writer.add_scalar(k, float(v), epoch)\n",
    "            \n",
    "    # сохрание, если лосс меньше всех предыдущих\n",
    "    if current_dict.get('val' + ' loss', START_LOSS) < min_loss:\n",
    "        min_loss = current_dict.get('val' + ' loss', START_LOSS)\n",
    "        current_dict['min_loss'] = min_loss\n",
    "        current_dict['last_saved_at'] = epoch\n",
    "        save_checkpoint_and_vars(weights_pne,\n",
    "                                 model=model,\n",
    "                                 optimizer=optimizer,\n",
    "                                 epoch=epoch,\n",
    "                                 min_loss=min_loss,\n",
    "                                 batch_size=batch_size,\n",
    "                                 history_dict=history_dict,\n",
    "                                 last_saved_at=current_dict['last_saved_at'])\n",
    "\n",
    "    # сохрание, если модель почти обучена\n",
    "    todo_stop_train = False\n",
    "    if not current_dict.get('val' + ' loss', None):\n",
    "        if current_dict['val' + ' loss'] < 0.5:\n",
    "            todo_stop_train = True\n",
    "            save_checkpoint_and_vars(weights_pne,\n",
    "                                     model=model,\n",
    "                                     optimizer=optimizer,\n",
    "                                     epoch=epoch,\n",
    "                                     min_loss=min_loss,\n",
    "                                     batch_size=batch_size,\n",
    "                                     history_dict=history_dict,\n",
    "                                     last_saved_at=current_dict['last_saved_at'])\n",
    "\n",
    "    if todo_stop_train:\n",
    "        print('train done))')\n",
    "        break\n",
    "\n",
    "        # if not todo_train:\n",
    "        # try:\n",
    "        #    current_dict['lr'] = scheduler.get_last_lr()[-1]\n",
    "        # except:\n",
    "        #    current_dict['lr'] = -1\n",
    "        # scheduler.step(float(current_dict['val' + ' loss']))\n",
    "\n",
    "    epoch = epoch + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d31b80",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "for k, v in current_dict.items():\n",
    "    if k[0] != \"_\":\n",
    "        print(k, v)\n",
    "for k, v in drawings.items():\n",
    "    print(k)\n",
    "    for type_, lines in v.items():\n",
    "        plt.plot(*lines, c=colors_dict[type_])\n",
    "    plt.gca().set_aspect(\"equal\")\n",
    "    plt.show()\n",
    "\n",
    "for k, v in history_dict.items():\n",
    "    print(k)\n",
    "    if k != \"epoch\" and k != \"min_loss\":\n",
    "        plt.plot(v)\n",
    "        plt.show()\n",
    "prev_time[0] = time.time()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c0e50e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d46476",
   "metadata": {},
   "source": [
    "##### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
